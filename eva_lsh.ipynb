{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:56:27.962296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 22:56:28.649981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import network\n",
    "import layer\n",
    "import layer_lsh\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "\n",
    "# import dataset\n",
    "from keras.datasets import mnist\n",
    "# load dataset\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# compute the number of labels\n",
    "num_labels = len(np.unique(y_train))\n",
    "# convert to one-hot vector\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# image dimensions (assumed square)\n",
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train, [-1, input_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "hidden_units = 256\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s = x_train[0:1000]\n",
    "y_train_s = y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:56:29.667892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:29.690417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:29.690677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:29.691687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:29.691924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:29.692089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:30.207527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:30.207726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:30.207868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 22:56:30.207983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4573 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "Epoch  1: 100% |██████████| 1000/1000, Accuracy: 0.3700, Loss: 0.0751;\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LayerLSH.__binary_vector_by_hash_vector() missing 1 required positional argument: 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m neural_network\u001b[39m.\u001b[39maddLayer(Layer(hidden_units, num_labels))\n\u001b[1;32m     15\u001b[0m [epoch_accuracy, epoch_time] \u001b[39m=\u001b[39m neural_network\u001b[39m.\u001b[39mfit(x_train_s, y_train_s, learning_rate\u001b[39m=\u001b[39mlearning_rate, epochs \u001b[39m=\u001b[39m epochs)\n\u001b[0;32m---> 16\u001b[0m y_hat \u001b[39m=\u001b[39m neural_network\u001b[39m.\u001b[39;49mpredict(x_test)\n\u001b[1;32m     18\u001b[0m metrics \u001b[39m=\u001b[39m CategoricalAccuracy()\n\u001b[1;32m     19\u001b[0m metrics\u001b[39m.\u001b[39mupdate_state(y_test, y_hat)\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/network.py:68\u001b[0m, in \u001b[0;36mNetwork.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     67\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__layers:\n\u001b[0;32m---> 68\u001b[0m         X \u001b[39m=\u001b[39m l\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/layer_lsh.py:54\u001b[0m, in \u001b[0;36mLayerLSH.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_table_num):\n\u001b[1;32m     53\u001b[0m     hash_vectors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_projections[i]\u001b[39m.\u001b[39mT)\n\u001b[0;32m---> 54\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__binary_vector_by_hash_vector, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, arr\u001b[39m=\u001b[39;49mhash_vectors, args\u001b[39m=\u001b[39;49mi) \u001b[39m|\u001b[39m mask\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m y\u001b[39m*\u001b[39mmask\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CS791-Project/lib/python3.11/site-packages/numpy/lib/shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    376\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    377\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    378\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 379\u001b[0m res \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    381\u001b[0m \u001b[39m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[1;32m    385\u001b[0m buff \u001b[39m=\u001b[39m zeros(inarr_view\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mshape, res\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/layer_lsh.py:66\u001b[0m, in \u001b[0;36mLayerLSH.__binary_vector_by_hash_vector\u001b[0;34m(self, vector, args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__binary_vector_by_hash_vector\u001b[39m(\u001b[39mself\u001b[39m, vector, args):\n\u001b[1;32m     65\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_dim, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m     hash_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__binary_vector_by_hash_vector(vector)\n\u001b[1;32m     67\u001b[0m     active_set \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash_tables[args][hash_value])\n\u001b[1;32m     68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask[active_set] \u001b[39m=\u001b[39m  \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: LayerLSH.__binary_vector_by_hash_vector() missing 1 required positional argument: 'args'"
     ]
    }
   ],
   "source": [
    "reload(network)\n",
    "reload(layer_lsh)\n",
    "from network import Network\n",
    "from layer_lsh import LayerLSH\n",
    "from layer import Layer\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "neural_network = Network()\n",
    "neural_network.addLayer(LayerLSH(input_size, hidden_units))\n",
    "neural_network.addLayer(LayerLSH(hidden_units, hidden_units))\n",
    "neural_network.addLayer(LayerLSH(hidden_units, hidden_units))\n",
    "neural_network.addLayer(Layer(hidden_units, num_labels))\n",
    "\n",
    "[epoch_accuracy, epoch_time] = neural_network.fit(x_train_s, y_train_s, learning_rate=learning_rate, epochs = epochs)\n",
    "y_hat = neural_network.predict(x_test)\n",
    "\n",
    "metrics = CategoricalAccuracy()\n",
    "metrics.update_state(y_test, y_hat)\n",
    "print(metrics.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LayerLSH.__binary_vector_by_hash_vector() got an unexpected keyword argument 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_hat \u001b[39m=\u001b[39m neural_network\u001b[39m.\u001b[39;49mpredict(x_test)\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/network.py:68\u001b[0m, in \u001b[0;36mNetwork.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     67\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__layers:\n\u001b[0;32m---> 68\u001b[0m         X \u001b[39m=\u001b[39m l\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/layer_lsh.py:54\u001b[0m, in \u001b[0;36mLayerLSH.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_table_num):\n\u001b[1;32m     53\u001b[0m     hash_vectors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_projections[i]\u001b[39m.\u001b[39mT)\n\u001b[0;32m---> 54\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__binary_vector_by_hash_vector, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, arr\u001b[39m=\u001b[39;49mhash_vectors, args\u001b[39m=\u001b[39;49mi) \u001b[39m|\u001b[39m mask\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m y\u001b[39m*\u001b[39mmask\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CS791-Project/lib/python3.11/site-packages/numpy/lib/shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    376\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    377\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    378\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 379\u001b[0m res \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    381\u001b[0m \u001b[39m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[1;32m    385\u001b[0m buff \u001b[39m=\u001b[39m zeros(inarr_view\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mshape, res\u001b[39m.\u001b[39mdtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: LayerLSH.__binary_vector_by_hash_vector() got an unexpected keyword argument 'args'"
     ]
    }
   ],
   "source": [
    "y_hat = neural_network.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('LSH-Deep_Learning-Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10d9af6cb6ad23fd6cb3b2b2da4eaf478aa7d823227bfd0644d333526c5f72fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
