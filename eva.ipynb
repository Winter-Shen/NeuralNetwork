{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 08:31:12.995164: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 08:31:13.676948: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from network import Network\n",
    "from layer_wta import LayerWTA\n",
    "from layer_lsh import LayerLSH\n",
    "from layer import Layer\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "\n",
    "import pickle\n",
    "\n",
    "# import dataset\n",
    "from keras.datasets import mnist\n",
    "# load dataset\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# compute the number of labels\n",
    "num_labels = len(np.unique(y_train))\n",
    "# convert to one-hot vector\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# image dimensions (assumed square)\n",
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size\n",
    "# resize and normalize\n",
    "x_train = np.reshape(x_train, [-1, input_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "hidden_units = 256\n",
    "learning_rate = 0.01\n",
    "\n",
    "function_num = 5\n",
    "table_num = 6\n",
    "\n",
    "top_k = 1-(1-(1/2**function_num))**table_num\n",
    "\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 08:31:19.321457: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Epoch  1:   3% |â–Ž         | 1854/60000, Accuracy: 0.257;"
     ]
    }
   ],
   "source": [
    "neural_network_wta = Network()\n",
    "neural_network_wta.addLayer(LayerWTA(input_size, hidden_units, top_k))\n",
    "neural_network_wta.addLayer(LayerWTA(hidden_units, hidden_units, top_k))\n",
    "neural_network_wta.addLayer(LayerWTA(hidden_units, hidden_units, top_k))\n",
    "neural_network_wta.addLayer(Layer(hidden_units, num_labels))\n",
    "\n",
    "[epoch_accuracy_wta, epoch_time_wta] = neural_network_wta.fit(x_train, y_train, learning_rate=learning_rate, epochs = epochs)\n",
    "y_hat = neural_network_wta.predict(x_test)\n",
    "\n",
    "metrics = CategoricalAccuracy()\n",
    "metrics.update_state(y_test, y_hat)\n",
    "print(metrics.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object successfully saved to \"../data/neural_network_wta.pkl\"\n"
     ]
    }
   ],
   "source": [
    "file_name = '../data/neural_network_wta.pkl'\n",
    "with open(file_name, 'wb') as file:\n",
    "    pickle.dump(neural_network_wta, file)\n",
    "    print(f'Object successfully saved to \"{file_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1:   0% |          | 236/60000, Accuracy: 0.093;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m neural_network_lsh\u001b[39m.\u001b[39maddLayer(LayerLSH(hidden_units, hidden_units, function_num\u001b[39m=\u001b[39mfunction_num, table_num\u001b[39m=\u001b[39mtable_num))\n\u001b[1;32m      5\u001b[0m neural_network_lsh\u001b[39m.\u001b[39maddLayer(Layer(hidden_units, num_labels))\n\u001b[0;32m----> 7\u001b[0m [epoch_accuracy_lsh, epoch_time_lsh] \u001b[39m=\u001b[39m neural_network_lsh\u001b[39m.\u001b[39;49mfit(x_train, y_train, learning_rate\u001b[39m=\u001b[39;49mlearning_rate, epochs \u001b[39m=\u001b[39;49m epochs)\n\u001b[1;32m      8\u001b[0m y_hat \u001b[39m=\u001b[39m neural_network_lsh\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m     10\u001b[0m metrics \u001b[39m=\u001b[39m CategoricalAccuracy()\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/network.py:52\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[0;34m(self, X, Y, learning_rate, epochs, progress)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m singleP:\n\u001b[1;32m     51\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 52\u001b[0m     y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__fit(X[[j]], Y[[j]])\n\u001b[1;32m     53\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     55\u001b[0m     \u001b[39m#ft[i][j] = f_time\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39m#bt[i][j] = b_time\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/network.py:21\u001b[0m, in \u001b[0;36mNetwork.__fit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__fit\u001b[39m(\u001b[39mself\u001b[39m, x, y) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[39m# Forwardpropogation\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__layers:\n\u001b[0;32m---> 21\u001b[0m         x \u001b[39m=\u001b[39m l\u001b[39m.\u001b[39;49mforwardPropagation(x)\n\u001b[1;32m     22\u001b[0m     y_hat \u001b[39m=\u001b[39m x\n\u001b[1;32m     23\u001b[0m     r \u001b[39m=\u001b[39m y_hat\u001b[39m-\u001b[39my\n",
      "File \u001b[0;32m~/Documents/NeuralNetwork/layer_lsh.py:53\u001b[0m, in \u001b[0;36mLayerLSH.forwardPropagation\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_dim, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask[\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m()\u001b[39m.\u001b[39munion(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_active_sets))] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_weight)\n\u001b[1;32m     54\u001b[0m \u001b[39m#y[0][self._mask] = 0\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next):\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neural_network_lsh = Network()\n",
    "neural_network_lsh.addLayer(LayerLSH(input_size, hidden_units, function_num=function_num, table_num=table_num))\n",
    "neural_network_lsh.addLayer(LayerLSH(hidden_units, hidden_units, function_num=function_num, table_num=table_num))\n",
    "neural_network_lsh.addLayer(LayerLSH(hidden_units, hidden_units, function_num=function_num, table_num=table_num))\n",
    "neural_network_lsh.addLayer(Layer(hidden_units, num_labels))\n",
    "\n",
    "[epoch_accuracy_lsh, epoch_time_lsh] = neural_network_lsh.fit(x_train, y_train, learning_rate=learning_rate, epochs = epochs)\n",
    "y_hat = neural_network_lsh.predict(x_test)\n",
    "\n",
    "metrics = CategoricalAccuracy()\n",
    "metrics.update_state(y_test, y_hat)\n",
    "print(metrics.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object successfully saved to \"../data/neural_network_lsh.pkl\"\n"
     ]
    }
   ],
   "source": [
    "file_name = '../data/neural_network_lsh.pkl'\n",
    "with open(file_name, 'wb') as file:\n",
    "    pickle.dump(neural_network_lsh, file)\n",
    "    print(f'Object successfully saved to \"{file_name}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('LSH-Deep_Learning-Project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10d9af6cb6ad23fd6cb3b2b2da4eaf478aa7d823227bfd0644d333526c5f72fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
